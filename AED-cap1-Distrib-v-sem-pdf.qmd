# AED - Análise Exploratória de Dados {#sec-AED}

> A **análise de dados** se refere aos métodos e estratégias para se olhar para os dados – a ***exploração***, ***organização*** e ***descrição*** de dados com auxílio de ***gráficos e resumos numéricos***. *Sua exploração conscienciosa permite que os dados iluminem a realidade*. Os Capítulos 1 ao 6 discutem a análise de dados [@Moore2023 , p. 6].

## Exploração de Dados (cap. 1)

> **"O que \[nos\] dizem os dados?”** é a primeira pergunta que fazemos em qualquer estudo estatístico. A **análise de dados** responde a essa questão por ***meio*** de uma ***exploração*** ampla dos dados. As ***ferramentas*** da análise de dados são ***gráficos***, como os *histogramas* e os *diagramas de dispersão*, ***e medidas numéricas***, como as *médias* e as *correlações*. No entanto, ao menos tão importantes quanto as *ferramentas*, são os ***princípios*** que ***organizam nosso pensamento** no exame dos dados* [@Moore2023 , p. 9].

Quanto aos ***princípios organizadores*** de um ***letramento*** ou pensamento estatístico, dois destacam-se na AED - Análise Exploratória de Dados:

> Um dos princípios organizadores da análise de dados consiste em \[**P~1~**\] ***olhar, primeiro, um item de cada vez e,*** \[**P~2~**\] ***depois, as relações entre estes***. Nossa apresentação segue esse princípio. Nos **Capítulos 1 a 3**, você estudará ***variáveis e suas distribuições***. Os **Capítulos 4 a 6** referem-se a ***relações*** entre variáveis. O Capítulo 7 faz uma revisão dessa parte do texto [@Moore2023 , p. 9].

Abaixo uma figura que iluistra o **Ciclo da Ciência de Dados**. Não se esqueça que a Estatística é "...a Ciência dos Dados! [@Moore2023 , p. 162].

![Ciclo da Ciência de Dados, suas 3 fases: **1 -** *Wrangle* (importar, organizar e transformar), **2 -** *Understand* (Transformar, Visualizar e Modelar; buscar melhor ajuste) e **3 -** *Communicate* (relatar) and *Replicate* (automatizar; app)](fig/2-data-science-wrangle-01.png){fig-align="center"}

A fase **1 -** ***Wrangle*** , quando inclusa um *levantamento de dados primários*, consome cerca de **80%** do tempo de uma pesquisa empírica [@Wickham2017R, p. ix, xi, 117]. Essa tarefa é uma verdadeira luta, que não costuma nos agradar.

Um similar ***conceito*** de **Ciclo da Ciência de Dados** (cf. [Curso-R](https://livro.curso-r.com/livro-curso-r)), agora associando-o aos principais `pacotes` do `R` que auxiliam cada fase ou etapa dentro de cada fase: notadamente o pacote `tidyverse`.

[![O tidyverse é um pacote guarda-chuva que consolida uma série de ferramentas que fazem parte do ciclo da ciência de dados. Fazem parte do {tidyverse} os pacotes {ggplot2}, {dplyr}, {tidyr}, {purrr}, {readr}, entre muitos outros, como é possível observar na figura.](fig/Conceito-Pacotes-R-ciclo-ciencia-de-dados.png){fig-alt="Conceito de Ciclo da Ciência de Dados" fig-align="center"}](https://livro.curso-r.com/4-2-tidyverse.html)

Conferir uma ***cheat sheet*** com pacotes em **R** bem mais completa em: <https://www.business-science.io/r-cheatsheet.html>.

As habilidades que, assim, espera-se de um ***cientista de dados*** são assim resumidas [@grolemund2014hands]:

![Three Core Skill sets of Data Science (GROLEMUND, 2017, p. 185)](fig/hopr_fig-10-04-3Core-SkillSets-OfDataScience_CP-DC-SR-p185-grolemund-2014.png){fig-align="center"}

Já a **Estatística**, melhor é referir-se à **Probabilidade e Estatística**, é conceituada como: ramo da Matemática aplicada que reune ***um conjunto de métodos*** para:

-   **planejar** estudos observacionais e experimentos aleatorizados em qualquer área do conhecimento científico, notadamente para pesquisas empíricas;
-   **coletar** dados **válidos** e **fidedignos**;
-   **organizar**,
-   **resumir**,
-   **apresentar** (listas, tabelas, diagramas, fórmulas, gráficos, grafos etc),
-   **analisar**,
-   **formular** e **testar** ***hipóteses*** e
-   **interpretar** conjuntos de **dados** e **informações**;
-   **elaborar** conclusões baseadas em **evidências** \[dados e informações válidos e fidedignos\] para
-   **apoiar** tomadas de **decisão** e para
-   **gerir** ou **controlar** um conjunto de **ações** em curso: qualidade, escala, cobertura, custos financeiros, eficiência, eficácia, efetividade etc. por meio de **indicadores** e de índices cuja ***aplicabilidade, comparabilidade, consistência e difusão*** possam ser **testadas e validadas** por uma comunidade de experts.

O Professor João Luiz Becker [@Becker2015] promove uma clara conceituação e distinção entre **dados** e **informações** e ilustra o ciclo em que a coleta e a extração deles inserem-se num processo mais amplo de obtenção de **conhecimento**, que prossegue e passa pela **decisão** e pela **ação**.

![](fig/Dados-Informacao-Decisao-Acao-Becker-fig11-p37-01.JPG){fig-align="center"}

Outros conceitos importantes são o de validade e de fidedignidade dos dados coletados, que podem ser compreendidos através da ilustração a seguir:

![Precisão ou Fidedignidade -x- Validade, Exatidão ou Acurácia](fig/preciscao-ou-fidedignidade-x-exatidao-ou-acuracia.png){fig-align="center"}

Conferir também a fig. 2.1 - distinção entre confiabilidade e validade, usando tiro ao alvo [@poldrack_pensamento_est_2025 , p. 13], que ainda conceitua *validade aparente*, *de constructo* e *preditiva*. Segundo esse autor:

> "A ***confiabilidade*** se refere à *consistência da localização dos disparos*, e a ***validade*** se refere à *acurácia* \[em sentido estrito\] *dos disparos em relação ao alvo*".

Perceba que, na prática, quando coletamos dados, desconhecemos a localização do alvo, ou seja, não sabemos onde se localiza o *verdadeiro e desconhecido valor do parâmetro populacional* de interesse.

Todavia, por meio de [***uma***]{.underline} ***amostra probabilística*** de ***tamanho adequado*** (n), é possível [***estimar***]{.underline} esse valor desconhecido de interesse da pesquisa, bem como sua [***acurácia***]{.underline} sob a [***suposição***]{.underline} uma ***coleta*** ***válida*** de ***dados fidedignos***.

Essa suposição só se sustenta se forem tomados todos os cuidados qualitativos de um adequado processo de amostragem probabilística, como, por exemplo, ***baixo*** [***viés não amostral***]{.underline} caracterizado por [@bolfarineBussab-2005elemAm , p. 9, 27-28]:

-   *baixa proporção* de *viés de subcobertura* (indivíduos não previstos no SR - Sistema de Referência), que são os *erros por* *omissão*;
-   baixa proporção de *erros por comissão*, pela *inclusão de elementos de outras populações* que *não* a *população alvo* ou *inclusão* ou *substituição voluntária* de elementos não sorteados na amostra probabilística (uma espécie de *subamostra*, de conveniência, pela *escolha voluntária* do pesquisador, ou mesmo probabilística, ambas *contaminantes* da *amostra probabilística*, ex.: substituir todas as `k` observações perdidas – não respostas ou NA's – da *amostra probabilística* de *tamanho* `n` por outras `k` observações, escolhidas por conveniência ou mesmo quando produto de *outra amostra aleatória de tamanho menor* `k` obtida da mesma população disponível);
-   *baixa proporção* de não respondentes ou *NA* (observações perdidas, parcial ou totalmente, no momento da coleta da amostra probabilística);
-   é necessário *avaliar os efeitos* (quantitativos, por subestimativa ou superestimativa, e qualitativos nos dados coletados) da *diferença de perfil* entre os *respondentes* e os *não respondentes* (NA's);
-   é necessário *avaliar os efeitos* do *eventual* *processo de imputação de dados*, caso tenha sido usado para suprir informações não coletadas (NA's), como, por exemplo, substituição dos NA's parciais pelo valor médio ou mediano do restante dos elementos da amostra probabilística;
-   *ausência* de *viés de resposta voluntária* (os indivíduos da amostra escolheram-se);
-   *ausência* de *viés de insuficiênia do questionário*, por problemas em sua redação (má compreensão do sentido da pergunta);
-   *ausência* de *viés de fraseado* das perguntas no levantamento por survey (questionário fechado);
-   *ausência* de *viés* por *efeito do entrevistador*, como seu seu modo de vestir, de postar ou de falar;
-   *ausência* de *viés de fraseado* das perguntas no levantamento por survey (por indução de resposta no questionário fechado, ou mesmo no aberto);
-   *ausência* de *erros de codificação* e de digitação dos dados tabulados;
-   *minimização* dos *erros de observação*, ocorridos durante o processo de levantamento de dados;
-   *minimização* dos *erros de medição*, em razão da *descalibração* do *instrumento utilizado* ou mesmo decorrentes de sua *inadequada aplicação* pelo *instrumentador*, ocorridos durante o *intervalo de tempo* decorrido no processo de levantamento de dados;
-   etc.

Trata-se de uma *lista meramente enumerativa*, que não afasta a ***necessidade***, por exemplo, de uma ***reflexão crítica*** quanto às *possíveis* ***variáveis ocultas*** ou ***não observadas*** pelo [***quadro de variáveis***]{.underline} que foi [***escolhido***]{.underline} pelo ***pesquisador*** (geralmente produto de sua conveniência e *não* de uma *revisão sistemática da literatura* - RSL) que serviu de base para a *coleta e tabulação* dos *dados primários* levantados, seja diretamente por ele (de preferência), ou por pessoa por ele para tanto bem treinada e testada.

::: callout-warning
Apenas quando [***todos***]{.underline} esses [***cuidados qualitativos***]{.underline} forem tomados para [***prevenção***]{.underline} contra a presença de [***vieses não amostrais***]{.underline} é que se poderá [***validar***]{.underline} uma *coleta probabílistica* de *dados amostrais* [***fidedignos***]{.underline}.
:::

A seguir a ideia de Ciclo da **Estatística Básica Inferencial**, que, após uma boa Análise Estatística Descritiva (AED) e Exploratória (AEE) dos dados, busca *chegar*, por meio do [***método indutivo***]{.underline}, a [***conclusões***]{.underline} [***válidas***]{.underline} ***e [confiáveis]{.underline}*** para ***toda*** a [***população amostrada***]{.underline} a partir de [***uma***]{.underline} [***amostra probabilística***]{.underline} [***válida***]{.underline} *e [**fidedígna**]{.underline}* daquela coletada.

![Ciclo da Inferência ou indução Estatística.](fig/inferencia.png){fig-align="center"}

O emprego desse método indutivo na inferência estatística pode ser visto na indicação da seta inferior esquerda ilustrada em um mais amplo **Conceito** de **Ciclo da Ciência**, cujo formato costuma ser designado como ***Diamond Shape*** [@Donovan2019-ug , p. 274-275]:

![Conceito de Ciclo da Ciência na forma de um *Diamond Shape* (DONOVAN; MICKEY, 2019, p. 274-275))](fig/DiamondShape-Donovan.jpg){fig-alt="Ciclo da Ciência" fig-align="center" width="628"}

Perceba-se, na ilustração acima, a importância da ***articulação*** da prévia da [***teoria***]{.underline}, de *base* juntamente com *uma teoria rival*, na busca de ***extração*** de [***evidências***]{.underline} a *partir* de [***um conjunto de dados validamente coletados***]{.underline}.

Primordial, para evitar ***Pràticas de Pesquisa Questionáveis*** – **PPQ**, que o pesquisador realize um [**pré-registro**]{.underline} (ex.: sistema [*ClinicalTrials.gov.*](https://clinicaltrials.gov./)) de pelo menos um par de hipóteses, *nula* (H~0~) e alternativa (H~a~), *adequadamente formuladas*, que ele pretende testar. Isso bem ***antes*** dele ***iniciar*** sua ***coleta de dados***, para prevenir e [***evitar***]{.underline} qualquer possibilidade de prática de [***HARKing***]{.underline} (*hypothesizing after the results are known*) ou de *p-hacking*, o que possibilita que o pesquisador [*reformule*]{.underline} uma [conclusão *post-hoc*]{.underline} ***como se*** fora uma [predição *a priori*]{.underline}, que goza de maior confiança, dado que ele, nesse caso, estaria indevidamente *reescrevendo sua teoria* de partida [@poldrack_pensamento_est_2025 , p. 266-267], a de base e a rival, com [*base nos conjunto de dados coletados*]{.underline} (uma espécie de *Teorização Fundamentada em Dados* - ***TFD ad hoc***, que é obtida por meio da indução e que seria então "testada" com base no mesmo conjunto de dados donde ela, *a posteriori*, proveio, ou seja, sob um indevido e *inválido viés de confirmação*, uma vez que as hipóteses, assim reelaboradas, claramamente hão de ajustar-se aos dados colhidos), ao invés de elaborar [***predições***]{.underline} ou [***conjecturas***]{.underline} [***deduzidas***]{.underline} das [***teorias***]{.underline} [***previamente escolhidas***]{.underline}, conforme muito bem ilustrado pelo *retângulo superior* e *seta superior direita* do ***diamond shape*** da figura acima.

Logo, é somente a [***qualidade***]{.underline} do [***desenho do experimento***]{.underline} (*Design of Experiment* – *D.o.E.* referido na *seta inferior direita* do mesmo *diamond shape*) que [***garante***]{.underline}, através do [***consenso***]{.underline} dos [***experts***]{.underline} que atuam na *específica área de conhecimento científico da pesquisa* proposta, muitas vezes denominado por [***crivo dos pares***]{.underline}, que vai muito além de uma *avaliação independente duplo cego* pelos *referees* dos periódicos científicos, porquanto é [***ônus***]{.underline} de [***qualquer pesquisador***]{.underline} *demonstrar* que [***aderiu***]{.underline} às seguintes [***boas práticas reproduzíveis***]{.underline} de pesquisa:

> ▶Decidir regras para finalizar a coleta de dados antes do seu início e elencá-la no artigo.
>
> ▶Coletar, pelo menos, 20 observações por unidade de análise ou fornecer uma justificativa convincente do custo da coleta de dados.
>
> ▶Listar todas as variáveis coletadas em um estudo.
>
> ▶Relatar todas as condições experimentais, incluindo manipulações malsucedidas.
>
> ▶Elencar como seriam os resultados estatísticos incluindo as observações eliminadas, se houver.
>
> ▶Relatar os resultados estatísticos sem a covariável se uma análise incluir uma covariável.
>
> **Replicação**
>
> Um dos balizadores da ciência é o conceito de replicação — ou seja, ***outros pesquisadores devem ser capazes de realizar o mesmo estudo e obter o mesmo resultado***. *Infelizmente*, conforme vimos o que aconteceu com o *Reproducibility Project* analisado anteriormente neste capítulo, *muitas descobertas [não]{.underline} são replicáveis*.
>
> A *melhor forma* de *assegurar* a *replicabilidade* de sua *pesquisa* é, primeiro, [*replicá-la por conta própria*]{.underline}; para alguns estudos, isso não será possível, mas *sempre que possível*, você *deve garantir* que [*sua descoberta se sustente em uma amostra nova*]{.underline}, que deve ter [*potência suficiente*]{.underline} para [*encontrar*]{.underline} o [*tamanho do efeito*]{.underline} de *interesse*; em *muitos casos*, isso [*exigirá*]{.underline} [*uma amostra maior do que a original*]{.underline}.
>
> É importante considerar alguns pontos quando se trata de replicação.
>
> [**Primeiro**]{.underline}, o fato de [***uma tentativa de replicação ser malsucedida não significa necessariamente que a descoberta original era falsa***]{.underline}; lembre que, com o [*nível padrão de 80% de potência*]{.underline}, [***ainda existe 1 chance em 5 de que o resultado não seja significativo***]{.underline}, [***mesmo que exista um efeito verdadeiro***]{.underline}.
>
> Por esse motivo, *queremos normalmente observar [**múltiplas replicações**]{.underline}* em *qualquer descoberta importante* [***antes de decidir se devemos ou não acreditar nela***]{.underline} e, em geral, queremos que as [***tentativas de replicação tenham níveis de potência maiores do que o original***]{.underline}.
>
> Infelizmente, [***muitas áreas***]{.underline}, incluindo a *Psicologia*, [***não adotaram***]{.underline} esse conselho \[essa *Regra de Boas Práticas de Pesquisa Reproduzível - PPQ*\] ao *longo* dos [***últimos anos***]{.underline}, [***levando***]{.underline} a [***descobertas***]{.underline} ***“[amplamente aceitas]{.underline}”*** que [***provavelmente se revelaram falsas***]{.underline}.
>
> No que diz respeito aos estudos de PES de Daryl Bem, uma grande tentativa de replicação envolvendo sete estudos *não conseguiu replicar as descobertas* (Galak et al, 2012).
>
> [**Segundo**]{.underline}, lembre-se de que o [***valor-p não nos fornece uma medida da verossimilhança de replicação de uma descoberta***]{.underline}.
>
> Conforme examinamos anteriormente, o [***valor-p***]{.underline} é [***uma afirmação sobre a verossimilhança dos dados***]{.underline}, [***considerando uma hipótese nula específica***]{.underline} ***\[sob a suposição de que Ho fosse verdadeira\]***; ele [***não indica nada***]{.underline} sobre a [***probabilidade***]{.underline} de que a [***descoberta***]{.underline} seja [***efetivamente verdadeira***]{.underline} (conforme aprendemos no Capítulo 11). Para [***saber***]{.underline} a [***verossimilhança de replicação***]{.underline}, [***precisamos saber a probabilidade de a descoberta ser verdadeira***]{.underline}, o que ***geralmente não sabemos***. [@poldrack_pensamento_est_2025 , p. 269-270]

Tudo isso sob [***pena***]{.underline} de sua [***pesquisa empírica***]{.underline} ser [***classificada***]{.underline} como [***facilmente contestável***]{.underline}, por ***adesão***, *voluntária* ou *involuntária*, às [**Práticas de Pesquisa Questionáveis – PPQ**]{.underline} [@poldrack_pensamento_est_2025 , p. 266-267].

Uma das modalidades de conceituar e aplicar a Probabilidade e Estatística é pela denominada **Estatística bayesiana**, ou seja, aquela apoiada no **conceito** de ***probabilidade condicional*** e no ***Teorema de Bayes***, ilustrado na figura a seguir:

![Teorema de Bayes para testar um par de Hipóteses (Ho: \~A e Ha: A) com suas probabilidades *a priori* mediadas e atualizadas por uma coleta de dados B que permite inferir as respectivas probabilidades *a posteriori* desse par. Que pode ser *reiterado* com novas coletas de dados C, D, ...](fig/fig5.4_BayesTheorem.JPG){fig-align="center"}

A partir do conceito de [*probabilidade condicional*]{.underline} e de [**probabilidade *a priori***]{.underline}, que se localiza no *primeiro fator* do *numerador* do *lado direito* da *igualdade* da *fórmula* da figura acima que *presenta* o [***Teorema de Byes***]{.underline}, chegou-se ao ***conceito*** de [***Fator de Bayes***]{.underline} (**FB**), que [***mede***]{.underline} as [***razões de chance***]{.underline} (*odds ratio*) entre a [***verossimilhança***]{.underline} ou [***probabilidade a priori***]{.underline} [***dos dados***]{.underline} sob a ***Hipótese Alternativa*** (a probabilidade dos dados empíricos colhidos [*supondo*]{.underline} que **H~a~** fosse Verdadeira) em [*relação à*]{.underline} [***verossimilhança***]{.underline} ou [***probabilidade a priori***]{.underline} [***dos dados***]{.underline} sob a *Hipótese Nula* (a probabilidade dos dados empíricos colhidos [*supondo*]{.underline} que **H~0~** fosse Verdadeira), traduzida pela seguinte expressão:

$$
FB = \frac{p(dados|H_a)}{p(dados|H_0)}
$$ {#eq-FB-FatorBayes}

Ou seja, o **FB** "...***Fator de Bayes caracteriza a verossimilhança relativa dos dados***, ***considerando duas hipóteses diferentes***" [@poldrack_pensamento_est_2025 , p. 140].

Esse **FB** - ***Fator de Bayes***, agora sim, é capaz de [***medir***]{.underline} a [***força***]{.underline} da [***evidência***]{.underline} do [***resultado***]{.underline} consistente na [***decisão***]{.underline} pela [***rejeição***]{.underline} da **H~0~** em *um* [***Teste de Significância da Hipótese Nula***]{.underline} (***NHST*** - *Null Huphoteses Significant Test*) [@poldrack_pensamento_est_2025 , p. 140-142], pois:

> Desse modo, [***um valor maior que 1 refletirá maior evidência***]{.underline} para Smith \[**H~a~**\], e [***um valor menor que 1 refletirá maior evidência***]{.underline} para Jones \[**H~0~**\].
>
> O [***fator de Bayes***]{.underline} resultante (**3325,26**) fornece [***uma medida das evidências***]{.underline} que [***os dados fornecem***]{.underline} em [***relação às duas hipóteses***]{.underline} — aqui, [***informa***]{.underline} que a [***hipótese do senador Smith***]{.underline} [***é mais fortemente respaldada pelos dados***]{.underline} do [***que***]{.underline} a [***hipótese do senador Jones***]{.underline}. [@poldrack_pensamento_est_2025 , p. 140]

Há um critério consensual na literatura de como se deve interpretar o Fator de Bayes.

> [interpretando os fatores de Bayes]{.smallcaps}
>
> ***Como sabemos se um fator de Bayes de 2 ou de 20 é eficaz ou ineficaz?***
>
> Existe [***uma diretriz geral***]{.underline} para a [***interpretação***]{.underline} dos [***fatores de Bayes***]{.underline} sugerida por [Kass e Raftery (1995)](https://www.andrew.cmu.edu/user/kk3n/simplicity/KassRaftery1995.pdf):

A tabela a seguir, cf. cap. 11 [@poldrack_pensamento_est_2025 , cap. 11, p. 143], resume esse [***critério de interpretação não discricionário***]{.underline}, pois consensuado na literatura.

A seguir carrega-se o conjunto de dados `NHANES`, que é muito trabalho ao longo de todo o livro de Poldrack.

Bem como o conjunto de pacotes necessários para gerar a tabela referida.

```{r}

library(tidyverse)
library(ggplot2)
library(cowplot)
library(boot)
library(MASS)
library(BayesFactor)
library(knitr)
theme_set(theme_minimal(base_size = 14))

set.seed(123456) # set random seed to exactly replicate results

# load the NHANES data library
library(NHANES)

# drop duplicated IDs within the NHANES dataset
NHANES <-
  NHANES %>%
  dplyr::distinct(ID, .keep_all = TRUE)

NHANES_adult <-
  NHANES %>%
  drop_na(Weight) %>%
  subset(Age >= 18)
```

Salvar o *data set* `NHANES` como arquivo `.csv` na pasta `out` deste Projeto.

```{r}

# Salvar esse dataframe no formato binário do R na pasta out
# Sua próxima importação ela virá com todos os tratamentos até aqui realizados:
# tipos de colunas preservados: <char>, <date>, <time>, <fctr>, <int>,
# 'A tibble':	6,779 × 76 [mais de 6 mil observações e 76 variáveis]
write_rds(NHANES, file = "out/NHANES.rds") # formato binário do R

# Salvar esse conjunto de dados tratado no formato .csv:
write.csv(NHANES,
          file      = "out/NHANES.csv",
          na        = "", # salvar campos NA como espaço vazio <blank>
          row.names = FALSE) # não salvar coluna com números das linhas
```

Então segue-se um script R, obtido com apoio do *copilot*, para geração da referida tabela da força do Fator de Bayes.

```{r}
#| label: tbl-evid-FBayes
#| warning: false
#| tbl-cap: "Fator Bayes - 6 classes de interpretações da Força da Evidência"

# Criar vetor com 6 faixas ou classes de Fator de Bayes
faixas_bf <- c("BF < 1",         # 1
                "1 ≤ BF < 3",    # 2
                "3 ≤ BF < 20",   # 3
               "20 ≤ BF < 150",  # 4
              "150 ≤ BF < 275",  # 5
               "BF ≥ 275")       # 6

# Criar vetor com 6 classes de interpretações da força da evidência
interpretacao <- c(
  "Evidência a favor da hipótese nula",                    # 1
  "Evidência fraca a favor da hipótese alternativa",       # 2
  "Evidência moderada a favor da hipótese alternativa",    # 3
  "Evidência forte a favor da hipótese alternativa",       # 4
  "Evidência muito forte a favor da hipótese alternativa", # 5
  "Evidência extrema a favor da hipótese alternativa"      # 6
)

# Gerar a tabela
tabela_bayes <- data.frame(
  Faixa_Fator_de_Bayes = faixas_bf,
  Forca_da_Evidencia   = interpretacao
)

# Exibir a tabela
library(knitr)
library(kableExtra)

tabela_bayes |> kable("html",
                      booktabs  = TRUE,
                      longtable = TRUE,
                      caption = "Fator Bayes - 6 classes de interpretações da Força da Evidência")  |>
  kable_styling(bootstrap_options = c("striped", "hover"),
                full_width = T)
```

É importante fixar esses *principais conceitos* que serão trabalhados nesta disciplina **CDE-a-DPP**, o que reclama incursionar em ***conceitos simples*** de **Estatística Básica**, como: *população, amostra, plano amostral, tabelas, variáveis (seus tipos), gráficos (seus tipos), resumos numéricos como média, desvio padrão, mediana, Amplitude Interquartil (AIQ), correlação, regressão* etc.

Relembra-se que a ferramenta ***statkey*** é um bom aplicativo *free on line* para exercitar esses conceitos. Experimente ela com nosso ***data set*** já organizado `obitjcsv.csv`, que se encontra na pasta `out` de nosso Projeto `CDE-a-DPP-2.Rproj`; clique aqui: <https://www.lock5stat.com/StatKey/index.html> para acessar esse aplicativo. No plano de ensino há diversas outras ferramentas referidas (cf. aula n. 2).

Uma opção *free and open* é o: [JASP](https://jasp-stats.org/ "0.19.3.0"), desenvolvido pela Universidade de Amsterdan, sem necessidade de aprender uma linguagem de programação.

Mãos à obra pessoal, salientando que as 2 fases, de **AED** (Análise Exploratória *Descritiva*) e de **AEI** (Análise Exploratória *Inferencial*), demandarão **20%** restante do tempo de uma pesquisa (80% é gasto com a coleta, organização e tratamento dos dados primários), costumam ser-nos bem *mais prazerosas*.

Nessa nova fase, bem mais atraente, o objetivo é *explorar os dados* em busca do **reconhecimento de padrões perceptíveis**. Todavia, cuidado com a possibilidade do *erro percepcional* ou com a prática de *HARKing* ou de *p-haking*, como já visto.

Gerar vários **gráficos** (barras, colunas, pizza, diagrama de ramo e folha, histogramas, *boxplot*, dispersão etc.) que permitam essa ***visualização*** e ***captura de padrões*** para cada ***tipo variável*** observada: categórica (nominal ou ordinal) ou quantitativa (discreta ou contínua).

A figura a seguir ilustra essa classificação dos tipos de variáveis [@escovedo_introducao_EpCD_2024 , p. 17].

![Tipos de Variáveis](fig/TiposDeVariaveis.png){fig-align="center"}

***Resumos dos dados*** são muito úteis: média e desvio padrão; mediana e AIQ (Amplitude Interquartil); resumo dos 5 números, coeficiente de variação, assimetria, curtose etc.

Bem como para investigar possibilidade de ***associação*** entre elas: a depender da combinação dos seus ***tipos***, por meio de ***testes estatísticos*** formais.

Gerar tabelas de dupla entrada ou de contigência, quando ambas forem categóricas, do tipo **factor** \<`fctr`\>.

Todavia, todas essas possibilidades de recorrer à *Data Science* e à Probabilidade e Estatística, no nosso caso, tomarão por **domínio** a interface do Direito com as Políticas Públicas.

De modo que, para resguardar um ***elemento comum*** com os dessas duas Ciências matemáticas aplicadas (já ilustrado acima), buscou-se evidenciar também uma ideia ou conceito de **Ciclo do Direito** e de **Ciclo das Políticas Públicas**, ilustrados nas figuras a seguir.

Primeiro uma possibilidade de **Ciclo do Direito** [@Neves2021-colPrincPP] segundo uma *perspectiva retórica* e considerando a distinção entre significantes do passado e significados do futuro quanto aos diversos *símbolos linguísticos* que compõem os *dispositivos normativos*, que não se confudem com um conceito de norma, que só se concretiza com sua decisão e aplicação presente a um caso concreto somente depois que alcançar a definitividade de *coisa julgada* [@Adeodato2014-UTRNJDO].

![Um Conceito de Ciclo do Direito](fig/Dois%20Mistérios.png){fig-align="center"}

Já o conceito de Ciclo de Políticas Públicas é bem difundido e pode ser resumido nas duas figuras a seguir, não se podendo contentar com sua idealização, mas também considerar as vicissitudes que perpassam suas práticas (Jannuzzi, 2024):

![Ciclo clássico de Políticas e Programas](fig/ciclo-PP-Januzi.png){fig-align="center"}

Que pode e deve ser dinamizado por meio da variável tempo, como na figura espiral a seguir.

![Espiral da implementação das Políticas e programas](fig/Espiral-Ciclo-PPs-jannuzzi.jpg){fig-align="center"}

Mas a *vida* do ciclo de uma Política Pública *como ela é* pode afastar-se dessas concepções idealizadas.

![A realidade da implementação de programas](fig/gyn-ciclo-implem-p10-como-ele-e.jpg){fig-align="center" width="680"}

## Um rápido exemplo

Procurar fazer uso dos pacotes do R acima mencionados.

### Preparar

Limpar e *setup* do ambiente a ser utilizado: limpar e preparar a *Environment*.

```{r setup, include=TRUE}

# Deletar os objetos da Global Environment
rm(list=ls())

# Padrão de saídas Rmarkdown
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)

# Instalar tidyverse caso não esteja já instalado
if (!require('tidyverse')) install.packages('tidyverse')
# Instalar pacote magrittr caso não esteja já instalado
if (!require("magrittr")) install.packages("magrittr")
# Instalar pacote mlr caso não esteja já instalado
if (!require("mlr")) install.packages("mlr")

# Carregar o pacote DBI na Global Environment: disponível para uso direto
library('tidyverse')
# Warning: package ‘tidyverse’ was built under R version 4.2.3
# Warning: package ‘ggplot2’ was built under R version 4.2.3
# Warning: package ‘tibble’ was built under R version 4.2.3
# Warning: package ‘tidyr’ was built under R version 4.2.3
# Warning: package ‘readr’ was built under R version 4.2.3
# Warning: package ‘purrr’ was built under R version 4.2.3
# Warning: package ‘dplyr’ was built under R version 4.2.3
# Warning: package ‘stringr’ was built under R version 4.2.3
# Warning: package ‘forcats’ was built under R version 4.2.3
# Warning: package ‘lubridate’ was built under R version 4.2.3
# ── Attaching core tidyverse packages # ──────────────────────────────────────────── tidyverse 2.0.0 ──
# ✔ dplyr     1.1.2     ✔ readr     2.1.5
# ✔ forcats   1.0.0     ✔ stringr   1.5.1
# ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
# ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
# ✔ purrr     1.0.2     
# ── Conflicts ────────────────────────────────────────────────────────────── # tidyverse_conflicts() ──
# ✖ dplyr::filter() masks stats::filter()
# ✖ dplyr::lag()    masks stats::lag()
# ℹ Use the conflicted package to force all conflicts to become errors

# Carregar o pacote magrittr na Global Environment: disponível para uso direto
library("magrittr")
# Attaching package: ‘magrittr’
# 
# The following object is masked from ‘package:purrr’:
# 
# set_names
# 
# The following object is masked from ‘package:tidyr’:
# 
#     extract

# Carregar o pacote mlr na Global Environment: disponível para uso direto
library("mlr")

# Carregar o pacote rmarkdown na Global Environment: disponível para uso direto
# library("rmarkdown")
```

### Importar

**1**. **Importar** o *data set*, o arquivo `obitjcsv.csv`, que se encontra na pasta `out` de nosso Projeto `CDE-a-DPP.Rproj`. Recomenda-se baixar a atualizar a última versão desse nosso projeto que se encontra compartilhado no google drive: <https://drive.google.com/drive/u/1/folders/1wm9jUo5XlBHqbQDRf9XevFbXcqkWogqt>

```{r}

# Importar como tibble o arquivo de dentro da pasta chamada out.
obitj_csv <- readr::read_csv(file   = "out/obitjcsv.csv",
                             # delim  = ",",
                             quote  = "\"",
                             locale = locale(
                               decimal_mark = ".",
                               encoding     = "UTF-8"
                               )
                             )

# cat - Concatenate And Print
cat("\n") # imprime no console (saída) uma linha em branco
cat("Estrutura do objeto R denominado obitj_csv:\n")
str(obitj_csv)

cat("\n")
cat("Nomes das 24 colunas do objeto obitj_csv:\n")
names(obitj_csv)

obitj_csv # tibble:447 × 24
```

### Transformar

**2**. **Transformar** esse *data set* para que criar as seguintes variáveis categóricas:

***Transformar***, antes, as variáveis tipo `char` que enquadram-se como factor: `fctr`.

```{r}

# para explicitar a ordem das categorias nas variáveis
# que medem níveis de escolaridades: esc1 e esc2
# variável categórica ordinal com 12 levels
series <- c(
  "1 ano",
  "2 ano",
  "4 ano",
  "5 ano",
  "6 ano",
  "7 ano",
  "8 ano",
  "9 ano",
  "1 série EM",
  "2 série EM",
  "3 série EM"
  )

# para explicitar a ordem das categorias nas variáveis
# que medem apenas 2 níveis (levels): s - sim / n - não
# nessas ordem (e não na ordem alfabética)
sim_n <- c(
  "s",
  "n"
  )

# Declaração de Variáveis tipo char já existentes como categóricas
obitj_csv <- obitj_csv %>% 
  mutate(sexo =                   # nova variável tipo <fctr>
           sexo %>%               # a partir da variável original sexo
           factor() %>%           # converte para o tipo factor
           forcats::fct_recode(   # forcats função para recodificar labels
             "F" = "f",      # novo à esquerda, antigo à direita
             "M" = "m"),     # F = Feminino, M = Masculino
         
         # mesma coisa com código mais condensado:
         cor = factor(cor), # mantidos os levels originais: branco, pardo, preto
         
         # variável corag = cor agragada em apenas 2 categorias
         corag = factor(corag), # mantidos os levels originais: branco, negro
         
         # variável esc1 = escolaridade 1, com 11 categorias
         esc1 =                  # nova variável tipo <fctr>
           esc1 |>               # a partir da variável original esc2
           factor( series ) |>   # converte para o tipo factor: 11/12 categorias
           forcats::fct_recode(  # forcats função para recodificar labels
             "1ano" = "1 ano",   # novo à esquerda, antigo à direita
             "2ano" = "2 ano",
             "3ano" = "3 ano",   # embora esta categoria ñ ocorra
             "4ano" = "4 ano",
             "5ano" = "5 ano",
             "6ano" = "6 ano",
             "7ano" = "7 ano",
             "8ano" = "8 ano",
             "9ano" = "9 ano",
             "1serieEM" = "1 série EM",
             "2serieEM" = "2 série EM",
             "3serieEM" = "3 série EM"
           ), # mantido nenhum label original
         
         # variável esc2 = escolaridade 2, com 10 categorias
         esc2 =                  # nova variável tipo <fctr>
           esc2 |>               # a partir da variável original esc2
           factor( series ) |>   # converte para o tipo factor: 12 categorias
           forcats::fct_recode(  # forcats função para recodificar labels
             "1ano" = "1 ano",   # embora esta categoria ñ ocorra
             "2ano" = "2 ano",   # novo à esquerda, antigo à direita
             "3ano" = "3 ano",   # categoria que ñ ocorre
             "4ano" = "4 ano",
             "5ano" = "5 ano",
             "6ano" = "6 ano",
             "7ano" = "7 ano",
             "8ano" = "8 ano",
             "9ano" = "9 ano",
             "1serieEM" = "1 série EM",
             "2serieEM" = "2 série EM",
             "3serieEM" = "3 série EM"
           ), # mantido nenhum label original
         
         # variável compfam = composição familiar, com 6 categorias
         compfam =               # nova variável tipo <fctr>
           compfam |>            # a partir da variável original compfam
           factor() |>           # converte para o tipo factor: 6 categorias
           forcats::fct_recode(  # forcats função para recodificar labels
             "mae"      = "mãe",      # novo à esquerda, antigo à direita
             "mae_padr" = "mãe + padrasto",
             "pai_mae"  = "pai + mãe",
             "pai_madr" = "pai + madrasta",
           ), # mantidos só 2 labels originais: pai, parentes
         
         # variável relpai = relação com pai, com 3 categorias
         relpai =                # nova variável tipo <fctr>
           relpai |>             # a partir da variável original relpai
           factor() |>           # converte para o tipo factor: 3 categorias
           forcats::fct_recode(  # forcats função para recodificar labels
             "auxilio"     = "auxílio", # novo à esquerda, antigo à direita
             "mesma_resid" = "mesma residência",
             "ausente"     = "ausente"
           ), # mantidos só um label original: ausente

         # variável usudrog = usuário de droga, com 2 categorias: s / n
         usudrog =                 # nova variável tipo <fctr>
           usudrog |>              # a partir da variável original usudrog
           factor( sim_n ),        # converte para o tipo factor: 2 categorias
           
        # variável subst = Substância entorpecente, com 4 categorias
         subst =                 # nova variável tipo <fctr>
           subst %>%             # a partir da variável original subst
           factor() %>%          # converte para o tipo factor: 4 categorias
           forcats::fct_recode(  # forcats função para recodificar labels
             "coca_crack"  = "cocaína / crack", # novo à esquerda, antigo à direita
             "lsd_ecstasy" = "lsd, ecstasy",
             "licita"      = "lícitas"
           ), # mantidos só um level original: maconha
         
         # variável orgcrim = organização criminosa, com 2 categorias: s / n
         orgcrim =                 # nova variável tipo <fctr>
           orgcrim |>              # a partir da variável original orgcrim
           factor( sim_n ),        # converte para o tipo factor: 2 categorias
         
         # variável morte = tipo de morte, com 2 categorias: nat / viol
         morte = factor(morte),    # mantida ordem dos 2 levels originais
         
         # variável paf = morte por perfuração de arma de fogo, com 2 cat: s / n
         paf =                     # nova variável tipo <fctr>
           paf |>                  # a partir da variável original paf
           factor( sim_n ),        # converte para o tipo factor: 2 categorias
         
         # variável circobt = circunstância do óbito, com 5 categorias
         circobt =                # nova variável tipo <fctr>
           circobt %>%            # a partir da variável original circobt
           factor() %>%           # converte para o tipo factor: 5 categorias
           forcats::fct_recode(   # forcats função para recodificar labels
             "MDIP" = "intervenção policial", # novo à esquerda, antigo à direita
             # MDIP = Morte Decorrente Intervenção Policial
             "MDCC" = "conflitos entre criminalidade",
             # MDIP = Morte Decorrente Conflitos entre Criminalidade
             "transito"      = "trânsito", 
             "outros"        = "Outros",
             "conf_fam_afet" = "conflito familiar / afetivo"
             )
         )

obitj_csv |> 
  head(25)
```

### Inspecionar

Uma rápida inspeção em `esc1` e `esc2`.

Por meio de uma contagem das categorias presentes em `esc1`, que corresponde à escolaridade do adolescente na data da primeira passagem pela DePAI, resumidas em uma **tabela**.

```{r}

obitj_csv |> 
  count(esc1)
```

Constata-se que a categoria `3ano` não ocorreu nos dados coletados para `esc1`.

A mesma tabela em um formato mais adequado para impressão em `.pdf`.

```{r}

library(gt)

tab.esc1 <- obitj_csv |> 
  count(esc1) |> 
  mutate(p = n / sum(n) * 100) |> 
  mutate(p = round(p, 1) )

actual_colnames <- colnames(tab.esc1) # [-1]
# actual_colnames
## [1] "esc1" "n"    "p"

spanners_and_header <- function(gt_tbl) {
  gt_tbl |> 
    cols_label(
    esc1 = "Escolaridade na data 1ª passagem",
    n    = "Frequência Absoluta",
    p    = "Em relação ao total"
    ) |> 
    tab_spanner(
      label   = md("**2016-2023**"),
      columns = 1
    ) |>
    tab_spanner(
      label   = md("**Contagem por séries**"),
      columns = c(2)
    ) |> 
    tab_spanner(
      label   = md("**Proporção percentual (%)**"),
      columns = c(3)
    ) |> 
    tab_header(
      title = "Goiânia (DePAI): Escolaridade de jovens em conflito com a lei",
      subtitle = "Na data da 1ª passagem pela Delagacia de Apuração de Atos Infracionais"
    ) 
}

tab.esc1 |> 
  gt() |> 
  # cols_label(.list = desired_colnames) |> 
  spanners_and_header()
```

E por meio de um **gráfico** de **Colunas** da variável categórica: `esc2`, que corresponde à escolaridade do adolescente na data do seu óbito.

```{r}
# uma primeira inspeção rápida
obitj_csv |> 
  ggplot( aes( esc2 ) ) +
  geom_bar() # orientation = "x"
```

Inverter os eixos x e y cima e também a ordem da variável categórica `esc2` plotada no eixo y.

Para obter um **gráfico** de **Barras**.

```{r}

obitj_csv |> 
  ggplot( aes( y = forcats::fct_rev(esc2) ) ) + # fct_rev() reverte a ordem das categorias
  geom_bar() # orientação barras horizontais
```

Que é *mais legível* que o gráfico de colunas.

Constata-se que as categorias `1ano` e `3ano` não ocorreram nos dados coletados para `esc2`.

## Exercício n. 8.4 - Amostragem no Campus

Você gostaria de iniciar um clube no campus para os que fazem psicologia, e você está interessado na ***proporção dos que fazem psicologia que adeririam***. A taxa seria de US\$35 e usada para pagar palestrantes convidados.

Você pergunta a cinco estudantes que fazem psicologia e que fazem seu seminário de psicologia se eles estariam interessados em aderir ao clube e quatro, dos cinco, respondem que sim. Esse método de amostragem é viesado? Se for, qual é a direção provável do viés?

```{r}
# Variável binária: 0 = não e 1 = sim
# amostra de tamanho n = 5
am = c(1, 1, 1, 1, 0)

# calcular tamanho da amostra
# sum(am)
cat("tamanho da amostra", "\n")
cat("n = ", sum(am))
cat("\n")

# mean(am) %>% round(4) * 100
cat("proporção dos que fazem psicologia que adeririam:", "\n")
cat(mean(am) %>% round(4) * 100, "%")
```

O método é viesado porque se trata de uma amostra de conveniência.

É esperada uma direção de superepresentação dessa amostra.

Logo, 80% apresenta um ***viés de superestimativa*** da proporção dos que fazem psicologia que adeririam ao Clube proposto.

## Exercício n. 8.12 - Desonestidade acadêmica

Como estrair uma AAE-c/TPPP no R.

```{r}
# Suponha que temos um data frame chamado 'dados' com uma coluna 'estrato' indicando o estrato de cada observação

# Exemplo de criação do data frame
set.seed(123) # Para reprodutibilidade
dados <- data.frame(
  id = 1:3954,
  estrato = c(
    rep(1, 1127),
    rep(2,  989),
    rep(3,  943),
    rep(4,  895)
    )
)

# Defina o tamanho total da amostra desejada
n_total <- 40

# Calcule o tamanho de cada estrato
tamanho_estrato <- table(dados$estrato)
# Visualize o tamanho de cada estrato
cat("Cálculo do Tamanho de cada estrato na Pop. Amostrada", "\n")
print(tamanho_estrato)

# Calcule o tamanho da amostra para cada estrato (proporcional ao tamanho do estrato)
n_estrato <- round(n_total * tamanho_estrato / sum(tamanho_estrato))


# Realize a amostragem estratificada
amostra <- do.call(rbind, lapply(1:4, function(e) {
  subset_estrato <- subset(dados, estrato == e)
  subset_estrato[sample(nrow(subset_estrato), n_estrato[e]), ]
}))

# Visualize a amostra
print(amostra)

# Visualize o tamanho de cada estrato na amostra: AAE c/TPP
cat("\n") # pular uma linha na saída
cat("Tamanho de cada estrato na Amostra: 1 AAE c/TPP", "\n")
print(table(amostra$estrato))
```

## Exercício n. 1.42 - Ela soa alta

**1**. **Importar** o *data set*, o arquivo `ex01-42hearing.csv`, que se encontra na pasta `dat > csv` de nosso Projeto `CDE-a-DPP.Rproj`. Recomenda-se baixar a atualizar a última versão desse nosso projeto que se encontra compartilhado no google drive: <https://drive.google.com/drive/u/1/folders/1wm9jUo5XlBHqbQDRf9XevFbXcqkWogqt>

```{r}

# Importar como tibble o arquivo de dentro da pasta chamada out.
audicao <- readr::read_csv(file   = "dat/csv/ex01-42hearing.csv",
                           # delim  = ",",
                           quote  = "\"",
                           locale = locale(
                             decimal_mark = ".",
                             encoding     = "UTF-8"
                             )
                           )

# cat - Concatenate And Print
cat("\n") # imprime no console (saída) uma linha em branco
cat("\n")
cat("Estrutura do objeto R denominado audicao:\n")
str(audicao)

cat("\n")
cat("Nomes da única coluna do objeto audicao:\n")
names(audicao)

audicao # tibble:24 × 1
```

### letra a

**2**. **Gerar** dois *diagramas de ramo e folha*, como pedido na letra do exercício 1.42 (p. 36).

Cf. <https://www.geeksforgeeks.org/r-stem-and-leaf-plots/>

```{r}

# R program to illustrate
# Stem and Leaf Plot

# using stem()
stem(audicao$numcorrect, scale = 0.5) # nessa escala os ramos não se dividem

```

Outro diagrama de árvore, agora com divisão dos ramos.

```{r}

# using stem()
stem(audicao$numcorrect, scale = 1)  # nessa escala os ramos dividem-se em dois
```

O segundo diagrama de ramos e folhas é mais informativo que o primeiro.

Porque mostra uma distribuição bimodal.

Todavia o *primeiro resume melhor os dados*, com forma de sino levemente assimétrica à esquerda. E com moda igual à mediana.

Com isso podemos considerar alcançados os objetivos da 1ª, 2ª e 3ª aulas desta disciplina **CDE-a-DPP**.

### Até breve

Dúvidas serão debeladas a cada aula!

![Até nosso pRRRóximo RRRencontro!](fig/ValeuGalera.png){fig-align="center"}
